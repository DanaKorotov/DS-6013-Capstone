{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f14ecd9-1ce1-4e8e-ad8a-49828a1276a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "# To check vessel names\n",
    "import re\n",
    "# To get exact lat/long\n",
    "#from shapely.wkt import loads\n",
    "# To map the ships or coastlines\n",
    "#import geopandas as gpd\n",
    "#from geopy.distance import geodesic\n",
    "# To find coastline distance\n",
    "from scipy.spatial import KDTree\n",
    "# For XgBoosting\n",
    "import xgboost as xgb\n",
    "import random\n",
    "# For CV with and weighted XGBoosting\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83ec4430-c1f2-4610-91b1-bfb6b9f093af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get preprocessed train and test data\n",
    "ais_train = pd.read_csv(\"xgboost_preprocessed_data/xgboost_data_new100.csv\")\n",
    "ais_test = pd.read_csv(\"xgboost_preprocessed_data/xgboost_data_newtest2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68b63a55-c949-4b23-b941-5e05408c14c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class semi_supervised_xgb:\n",
    "    def __init__(self, class_1, class_0, unknown):\n",
    "        '''\n",
    "        Inputs:\n",
    "            class_1: A dataframe of observations you think are part of class 1, with x and y variables included\n",
    "            class_2: A dataframe of observations you think are part of class 0, with x and y variables included\n",
    "            unknown: A dataframe of observations of unknown class, with x and y variables included\n",
    "\n",
    "        Methods:\n",
    "            xgboost: Takes in labeled and unlabeled data and returns an XGBoost model\n",
    "        '''\n",
    "        # Define important things\n",
    "        self.class_1_og = class_1\n",
    "        self.class_0_og = class_0\n",
    "        self.unknown_og = unknown\n",
    "        self.class_1 = class_1\n",
    "        self.class_0 = class_0\n",
    "        self.unknown = unknown\n",
    "        self.boost = 0\n",
    "        # Define to keep track of iterations done\n",
    "        self.boost_rounds_completed = 0\n",
    "\n",
    "    def xgboost(self, features, y_name, num_rounds = 11, k_cv = 7, boost_rounds = 4000,\n",
    "                np_seed = 4200, xgb_seed = 98765, \n",
    "                boost_params = {\n",
    "                    'objective': 'binary:logistic',  # Binary classification objective \n",
    "                    'eval_metric': 'logloss',  # Evaluation metric\n",
    "                    },\n",
    "                learning_rates = [.01], \n",
    "                verbose = True, \n",
    "                class_1_prob = .95, class_0_prob = .05): \n",
    "        '''\n",
    "        Description: \n",
    "            Uses xgboost to self train a final xgboost model and outputs it\n",
    "        \n",
    "        Inputs:\n",
    "            features: A list of the x variables in the given data\n",
    "            y_name: The name of the y variable in the given data\n",
    "            num_rounds: How many rounds of reclassification to use\n",
    "            k_cv: How many cross-validation folds to use in the XGBoost\n",
    "            boost_rounds: The number of rounds to run the XGBoost\n",
    "            np_seed: Before setting the cross-validation folds, this sets the seed for replicability\n",
    "            xgb_seed: The seed to use in the XGBoosts for replicability\n",
    "            boost_params: Parameters to use in the XGBoost models. Defaults to logloss on a binary classification. \n",
    "            learning_rates: A list of learning rates to use in the XGBoost models\n",
    "            verbose: If True, prints the model's progress\n",
    "            class_1_prob: If this number is met or exceeded by a model's given probability, a given observation is reclassified into class 1\n",
    "            class_0_prob: If this number is not met by a model's given probability, a given observation is reclassified into class 0\n",
    "\n",
    "        Outputs:\n",
    "            xgboost model of class xgboost.core.Booster\n",
    "        '''\n",
    "        # Print out starting numbers:\n",
    "        if verbose:\n",
    "            print(f\"Pre-modeling: {len(self.class_1)} of class 1 and {len(self.class_0)} of class 0 with {len(self.unknown)} out of model\")\n",
    "        unassigned = len(self.unknown)\n",
    "        for i in range(1, num_rounds + 1):\n",
    "            self.boost_rounds_completed += 1\n",
    "            model_data = pd.concat([self.class_1, self.class_0]).reset_index(drop = True)\n",
    "            x_features = model_data[features]\n",
    "            y_feature = model_data[y_name]\n",
    "            # Get sample weights\n",
    "            sample_weights = compute_sample_weight(\n",
    "                class_weight = 'balanced',\n",
    "                y = y_feature \n",
    "            )\n",
    "            # Set random seed\n",
    "            np.random.seed(np_seed) # Set seed\n",
    "            # Make DMatrix with weights to avoid issues with imbalanced data\n",
    "            x_mat = xgb.DMatrix(x_features, label = y_feature, weight = sample_weights)\n",
    "            # Make folds for CV\n",
    "            cv_folds = StratifiedKFold(n_splits=k_cv, shuffle=True, random_state=42)\n",
    "            # Get that CV in\n",
    "            best_rmse = float('inf')\n",
    "            for lr in learning_rates:\n",
    "                # Update learning rate in parameters\n",
    "                boost_params['eta'] = lr\n",
    "            \n",
    "                # Perform cross-validation\n",
    "                cv_results = xgb.cv(params = boost_params, \n",
    "                                    dtrain = x_mat,  \n",
    "                                    num_boost_round = boost_rounds, \n",
    "                                    nfold = k_cv, \n",
    "                                    folds = cv_folds,\n",
    "                                    metrics = 'logloss', \n",
    "                                    early_stopping_rounds = 12, \n",
    "                                    stratified = True,\n",
    "                                    seed = xgb_seed)\n",
    "                \n",
    "                if cv_results['test-logloss-mean'].min() < best_rmse:\n",
    "                    best_rmse = cv_results['test-logloss-mean'].min()\n",
    "                    best_lr = lr\n",
    "                    optimal_rounds = cv_results['test-logloss-mean'].idxmin() + 1\n",
    "\n",
    "            # Perform the optimized boost \n",
    "            boost_params['eta'] = best_lr\n",
    "            real_boost = xgb.train(params = boost_params, dtrain = x_mat, \n",
    "                                   num_boost_round = optimal_rounds)\n",
    "            test_features = self.unknown[features]\n",
    "            test_mat = xgb.DMatrix(test_features)\n",
    "            # Make predictions \n",
    "            predictions = real_boost.predict(test_mat) \n",
    "            with_probs = pd.concat([self.unknown, pd.DataFrame(predictions)], axis = 1)\\\n",
    "                .rename(columns = {0: 'prob_1'})\n",
    "            # Move out-of-model rows into correct DataFrames \n",
    "            self.class_1 = pd.concat([self.class_1,\n",
    "                                      with_probs.query(f\"prob_1 >= {class_1_prob}\")\\\n",
    "                                        .drop(['prob_1'], axis = 1)])\n",
    "            self.class_1[y_name] = 1\n",
    "            self.class_0 = pd.concat([self.class_0,\n",
    "                                    with_probs.query(f\"prob_1 < {class_0_prob}\")\\\n",
    "                                        .drop(['prob_1'], axis = 1)])\n",
    "            self.class_0[y_name] = 0\n",
    "            self.unknown = with_probs.query(f\"prob_1 < {class_1_prob} & prob_1 >= {class_0_prob}\")\\\n",
    "                .drop(['prob_1'], axis = 1)\n",
    "            # Print statement: \n",
    "            if verbose:\n",
    "                print(f'''Round {self.boost_rounds_completed}: {len(self.class_1)} probable nets and {len(self.class_0)} probable ships with {len(self.unknown)} out of model. \n",
    "LR of {best_lr} for {optimal_rounds} rounds''')\n",
    "            if (len(self.unknown) == 0):\n",
    "                if verbose:\n",
    "                    print('Stopping early: Out of unassigned ships')\n",
    "                break\n",
    "            if (len(self.unknown) == unassigned):\n",
    "                if verbose:\n",
    "                    print('Stopping early: Progress finished')\n",
    "                break\n",
    "            unassigned = len(self.unknown) # To use next loop \n",
    "        self.boost = real_boost\n",
    "        return real_boost # return best XGBoost model at the end\n",
    "    \n",
    "    def reset(self):\n",
    "        ''' \n",
    "        Resets the labels to their original form\n",
    "        '''\n",
    "        self.class_0 = self.class_0_og\n",
    "        self.class_1 = self.class_1_og\n",
    "        self.unknown = self.unknown_og\n",
    "        self.boost_rounds_completed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "705641c1-34ba-4684-9738-3bce925809e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find the ones we think are def nets and def not nets\n",
    "max_red_flags = ais_train.red_flags.max()\n",
    "prob_nets = ais_train.query(\"red_flags >= 3 & net_name\").copy().reset_index(drop=True)\n",
    "del max_red_flags\n",
    "prob_nets['net'] = 1\n",
    "prob_ships = ais_train.query(\"red_flags == 0\").copy().reset_index(drop=True)\n",
    "prob_ships['net'] = 0\n",
    "out_of_model = ais_train.query(\"(red_flags > 0) & ((net_name == False) | ((net_name == True) & (red_flags < 3)))\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe7ec525-20c3-4c66-b026-8ea15c4195f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-modeling: 14260 of class 1 and 52015 of class 0 with 151281 out of model\n",
      "Round 1: 63272 probable nets and 107866 probable ships with 46418 out of model. \n",
      "LR of 0.03 for 1127 rounds\n",
      "Round 2: 63356 probable nets and 108052 probable ships with 46148 out of model. \n",
      "LR of 0.03 for 1972 rounds\n",
      "Round 3: 63403 probable nets and 108066 probable ships with 46087 out of model. \n",
      "LR of 0.03 for 1770 rounds\n",
      "Round 4: 63433 probable nets and 108077 probable ships with 46046 out of model. \n",
      "LR of 0.03 for 1454 rounds\n",
      "Round 5: 63487 probable nets and 108093 probable ships with 45976 out of model. \n",
      "LR of 0.03 for 1877 rounds\n"
     ]
    }
   ],
   "source": [
    "train = semi_supervised_xgb(prob_nets, prob_ships, out_of_model)\n",
    "train_boost = train.xgboost(learning_rates = [.03], num_rounds = 5, k_cv = 3, boost_rounds = 6000,\n",
    "                            features = ['speed_0', 'speed_med', 'speed_99', 'speed_std', \n",
    "                                        'dist_med', 'dist_99', 'dist_std', 'x_0', 'x_med', \n",
    "                                        'x_99', 'x_std', 'y_0', 'y_med', 'y_99', 'y_std'], y_name = 'net', \n",
    "                            class_0_prob = .015, class_1_prob = .985)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7b7bbe2-9dcf-41ac-9882-d97a52327e4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red_flags\n",
      "0    15.180662\n",
      "1    47.582545\n",
      "2    79.010829\n",
      "3    91.224192\n",
      "4    79.979253\n",
      "dtype: float64\n",
      "net_name\n",
      "False    48.439598\n",
      "True     85.442818\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on different time's data\n",
    "test_mat = xgb.DMatrix(ais_test[['speed_0', 'speed_med', 'speed_99', 'speed_std', 'dist_med', 'dist_99', \n",
    "                                 'dist_std', 'x_0', 'x_med', 'x_99', 'x_std', 'y_0', 'y_med', 'y_99', 'y_std']])\n",
    "test_preds = train_boost.predict(test_mat)\n",
    "# Make predictions \n",
    "if \"prob_net\" in ais_test.columns:\n",
    "    ais_test = ais_test.drop(columns=[\"prob_net\"])\n",
    "ais_test = pd.concat([ais_test.reset_index(drop = True), \n",
    "                      pd.DataFrame(test_preds)], \n",
    "                     axis = 1)\\\n",
    "    .rename(columns = {0: 'prob_net'})\n",
    "\n",
    "print(\n",
    "    (ais_test[ais_test['prob_net'] >= 0.5].groupby('red_flags').size() / ais_test.groupby('red_flags').size() * 100).fillna(0)\n",
    ")\n",
    "print(\n",
    "    (ais_test[ais_test['prob_net'] >= 0.5].groupby('net_name').size() / ais_test.groupby('net_name').size() * 100).fillna(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e972207-3551-460c-8621-a29a7cc4e1d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy is:  0.8910\n",
      "The test sensitivity is:  0.9153\n",
      "The test specificity is:  0.8482\n",
      "The test loss is:  0.2921\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "ais_test['net'] = np.where((ais_test['net_name'] == True) & (ais_test['red_flags'] >= 3), 1, np.where(ais_test['red_flags'] == 0, 0, np.nan))\n",
    "ais_test2 = ais_test.dropna(subset = ['net']).copy()\n",
    "ais_test2['class_net'] = ais_test2['prob_net'] >= .5\n",
    "test_acc = ((ais_test2['class_net']) == ais_test2['net']).sum()/len(ais_test2)\n",
    "test_sensitivity = sum((ais_test2['class_net']) & (ais_test2['net'] == True))/(sum((ais_test2['class_net']) & (ais_test2['net'] == True)) + sum((ais_test2['class_net'] == False) & (ais_test2['net'] == True)))\n",
    "test_specificity = sum((ais_test2['class_net'] == False) & (ais_test2['net'] == False))/(sum((ais_test2['class_net'] == False) & (ais_test2['net'] == False)) + sum((ais_test2['class_net']) & (ais_test2['net'] == False)))\n",
    "test_loss = log_loss(ais_test2['net'], ais_test2['prob_net'])\n",
    "print(f\"The test accuracy is: {test_acc: .4f}\")\n",
    "print(f\"The test sensitivity is: {test_sensitivity: .4f}\")\n",
    "print(f\"The test specificity is: {test_specificity: .4f}\")\n",
    "print(f\"The test loss is: {test_loss: .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3efd06e8-18b1-4f7d-a451-8a538d621ed4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'speed_0': 8.498777389526367,\n",
       " 'speed_med': 23.83993148803711,\n",
       " 'speed_99': 16.889787673950195,\n",
       " 'speed_std': 5.401068210601807,\n",
       " 'dist_med': 6.849855422973633,\n",
       " 'dist_99': 7.31329870223999,\n",
       " 'dist_std': 5.056441307067871,\n",
       " 'x_0': 30.66214370727539,\n",
       " 'x_med': 13.663167953491211,\n",
       " 'x_99': 30.82803726196289,\n",
       " 'x_std': 6.634103775024414,\n",
       " 'y_0': 48.76719284057617,\n",
       " 'y_med': 12.533854484558105,\n",
       " 'y_99': 16.095462799072266,\n",
       " 'y_std': 6.234163284301758}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_boost.get_score(importance_type = 'gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bc55c62-7d13-4ad7-ba3e-9ac24fa0fc51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_boost.save_model('models/xgboost_new.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e489d163-b2d8-4a06-a56f-6153e004073f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d752c404-f92c-40c8-b0d0-20d8024c3de2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c85fac-eca2-4fd8-a86e-cf8ff026bed3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
